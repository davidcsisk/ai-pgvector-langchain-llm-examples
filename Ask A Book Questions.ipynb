{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d615a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain --upgrade\n",
    "# Version: 0.0.149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "241bde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install unstructured\n",
    "#!pip install pinecone-client\n",
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ddf3d",
   "metadata": {},
   "source": [
    "OpenAI provides an API to their pre-trained LLM (large language model).  Pinecone provides an API to their vector database, which is the where the vector embeddings from the PDF document are stored and queried. The Langchain framework provides a way to tie it all together, using the PDF file that you ran through the model and stored the resulting vector embeddings in Pinecone in conjunction with the existing LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d4a04",
   "metadata": {},
   "source": [
    "You will need to register an account at OpenAI to get an API key.  (You will also need to give them a credit card number before you can use the API...they won't charge the card though until you've exhausted for you free $18 credit. Just set the guardrails they provide to make sure you don't get any crazy charges, and don't share your API key.)\n",
    "\n",
    "You'll also need to register for an account with pinecone and get your API key for that as well. Just follow the instructions in their \"Getting started\" page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader = UnstructuredPDFLoader(\"pythondatasciencehandbook.pdf\")\n",
    "loader = UnstructuredPDFLoader(\"Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-Oâ€™Reilly-Media-2019.pdf\")\n",
    "\n",
    "# I'm going to use pythondatasciencehandbook.pdf...update: could not get this one to load for some reason.\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdac23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 946237 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "879873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 1199 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "373e695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e093ef3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the API keys from the environment variables\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV')\n",
    "#print(PINECONE_API_KEY, PINECONE_API_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"langchaintest\" # put in the name of your pinecone index here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c16349",
   "metadata": {},
   "source": [
    "Before the next cell will execute without errors, you must go to your Pinecone account and create a new index called \"langchaintest\".  I needed 1536 dimensions for this book (as indicated by an error message first attempt), and for the rest of the settings I chose defaults.  This will take a while to load the vector embeddings in Pinecone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "388988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34929595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's query it without the context of OpenAI's LLM...we'll just get phrases from the book back.\n",
    "query = \"Which machine learning algorithms can be trained incrementally?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e0f5b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finally, if your system needs to be able to learn autonomously and it has limited resources (e.g., a smartphone application or a rover on Mars), then carrying around large amounts of training data and taking up a lot of resources to train for hours e'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example of the first document that was returned\n",
    "docs[0].page_content[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8782a945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finally, if your system needs to be able to learn autonomously and it has limited resources (e.g., a smartphone application or a rover on Mars), then carrying around large amounts of training data and taking up a lot of resources to train for hours every day is a showstopper.\\n\\nFortunately, a better option in all these cases is to use algorithms that are capable of learning incrementally.\\n\\nOnline learning\\n\\nIn online learning, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called mini-batches. Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives (see Figure 1-13).\\n\\nFigure 1\\n\\n\\n\\n13. Online learning\\n\\nOnline learning is great for systems that receive data as a continuous flow (e.g., stock prices) and need to adapt to change rapidly or autonomously. It is also a good option\\n\\n16\\n\\n|\\n\\nChapter 1: The Machine Learning Landscape'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f67ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which machine learning algorithms can be trained incrementally?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3dfd2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Online learning algorithms can be trained incrementally. Examples include Reinforcement Learning algorithms and Support Vector Machines.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e45e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"List which machine learning algorithms do not require one-hot encoded data?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf523cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' k-Nearest Neighbors, Linear Regression, Logistic Regression, Support Vector Machines (SVMs), Decision Trees and Random Forests, and Neural networks.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6ffbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
